{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thesis, I implicitly suggested that association rule approach alone without any corrections is a dead end. We will now show the reasons behind this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this guide we will be using our custom set of transactions due to its tiny size, because the execution is done in a small amount of time, as opposed to our real dataset with which the computation using either Apriori or FP-Growth algorithm from custom libraries would be unnecessary slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = ['beer', 'water', 'milk']\n",
    "alien = ['beer', 'red', 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [human, alien]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will show the problems with FP-Growth algorithm from custom library called pyfpgrowth, than we will show the Apriori approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FP-Growth algorithm implementation from pyfpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfpgrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation expects as an input a list of transactions, where items are represented in integers. We can use LabelEncoder from scikit-learn for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit([x for y in entries for x in y])\n",
    "labeled_entries = [encoder.transform(entry) for entry in entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed the labeled data to the algorithm and find frequent patterns. The threshold is set to 0, so every transaction is recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 0\n",
    "patterns = pyfpgrowth.find_frequent_patterns(labeled_entries, support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the desired frequent patterns are found, the algorithm can generate rules based on them. The confidence is also set to 0, so every possible rule is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a quick look how the rules look like, we can print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('beer', 'milk') ['water']\n",
      "('beer',) ['orange']\n",
      "('orange', 'red') ['beer']\n",
      "('milk',) ['beer' 'water']\n",
      "('beer', 'water') ['milk']\n",
      "('orange',) ['beer']\n",
      "('beer', 'red') ['orange']\n",
      "('red',) ['beer']\n",
      "('beer', 'orange') ['red']\n",
      "('milk', 'water') ['beer']\n",
      "('water',) ['beer']\n"
     ]
    }
   ],
   "source": [
    "for rule in rules:\n",
    "    print(tuple(encoder.inverse_transform(rule)), encoder.inverse_transform(rules[rule][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problem here is, that we cannot set the maximal lenght of a rule to be in shape of {x} -> {y} as suggested in thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem is the 'incompleteness' of the generated rules. Rules {(beer, milk) -> (water); (beer, water) -> (milk)} are present, but when it comes to milk, only (milk, water) -> (beer) showed up. The rule (milk, beer) -> (water) is actually missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, this implementation cannot be used for the lack of its API (missing option for maximal lenght of a rule). If we would forget about the maximal length of a rule, the only way to use this algorithm would be to use all the variations of rules (which would end up with a horrible space complexity). But even when using the algorithm this way, it is still not a correct apporach due to its incompleteness of generated rules as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Apriori algorithm implementation from apyori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library has a better API than the FP-Growth algorithm from pyfpgrowth, but it is unfortunatelly very slow in computing the rules from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association rule produces rules as an output. Each rule generally contains three main attributes. Confidence, support and optionally lift. If you want to know more about what each means, you can read about it in the thesis attached to this guidelines in chapter 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we set up the occurence of an item to number 1. This means that the algorithm will recognize every transaction in dataset, because the transaction must appear \"at least 1 times\" in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the algoritm \"understand\" what we mean, we need to convert the occurence to support. Again, more detailed information about how the association rule algorithms work can be found in the attached thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support number that will be used in apriori algorithm: 0.5\n"
     ]
    }
   ],
   "source": [
    "support_num = occurence / len(entries)\n",
    "print('Support number that will be used in apriori algorithm:', support_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence will be set to 0, again for the example purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, documentation says that we can specify parameter max_length - the maximum length of relations. So I set the maximal lenght of a rule to be 2. The reason behind this is described in attached thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apriori algorithm is set and we can generate rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(entries, min_support=support_num, min_confidence=confidence, max_lenght=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how these rules look in a pretty printed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beer\n",
      "support:  1.0\n",
      "confidence:  1.0\n",
      "lift: 1.0\n",
      "\n",
      "milk\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "orange\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "red\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "water\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "milk -> beer\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "orange -> beer\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "red -> beer\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "water -> beer\n",
      "support:  0.5\n",
      "confidence:  0.5\n",
      "lift: 1.0\n",
      "\n",
      "water -> milk\n",
      "support:  0.5\n",
      "confidence:  1.0\n",
      "lift: 2.0\n",
      "\n",
      "orange -> red\n",
      "support:  0.5\n",
      "confidence:  1.0\n",
      "lift: 2.0\n",
      "\n",
      "water -> milk -> beer\n",
      "support:  0.5\n",
      "confidence:  1.0\n",
      "lift: 2.0\n",
      "\n",
      "orange -> red -> beer\n",
      "support:  0.5\n",
      "confidence:  1.0\n",
      "lift: 2.0\n",
      "\n",
      "number of rules:  13\n"
     ]
    }
   ],
   "source": [
    "iterations = 0\n",
    "for item in association_rules:\n",
    "\n",
    "    print(' -> '.join(item[0]))\n",
    "\n",
    "    print('support: ', str(item[1]))\n",
    "    print('confidence: ', str(item[2][0][2]))\n",
    "    print('lift: ' + str(item[2][0][3]))\n",
    "    print()\n",
    "    iterations += 1\n",
    "\n",
    "print(\"number of rules: \", iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But unfortunatelly again, we can see at the end that the rules were somehow expanded. The last two rules should not be there, because we specified the maximal lenght of the rule to be 2, but these rules happen to have a lenght of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a custom algorithm implemented 'from scratch' should be the best solution, but the target of the thesis was rather to use an existing API available in Python, so I did not include these models in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
