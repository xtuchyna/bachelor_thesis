{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results by trivial testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a trivial test of how the trained recommender systems are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load both our recommender models saved from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.Word2Vec.load('dependencies_recommender_w2v_cbow')\n",
    "model_skipgram = gensim.models.Word2Vec.load('dependencies_recommender_w2v_skipgram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then as a test dataset, we load the whole dependencies dataset we extracted to lists of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracted_dependencies.csv', 'r') as csv_file:\n",
    "    entries_csv = csv.reader(csv_file, delimiter=',')\n",
    "    test_entries = list(entries_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplicity we are going to use a trivial testing method. We randomly select a test_entry from the test_entries, randomly pop out one item from the test_entry and then check if the suggestions made by the recommender model contained the popped out entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select how much of these tests can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify how much missing_entries will model suggest. Let's set the limit to one hundred suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin testing the both models. We are going to need the random module for randomly selecting the indexes of selected entries and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a measurement the ratio of succesful:unsuccessful will be at the end calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_suggestions_cbow = 0\n",
    "successful_suggestions_skipgram = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that I did not process the dataset well. I actually forgot to exclude the transactions that contained only one item, which are in terms of analyzing relations between dependencies unuseful. This teaches us a lesson to always think about how the data would be selected - if right choices are not made, the model and usage implementation can greatly suffer from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < test_iterations:\n",
    "    test_entry = test_entries.pop(randint(0, len(test_entries)-1))\n",
    "    if len(test_entry) <= 1:\n",
    "        continue\n",
    "    missing_dependency = test_entry.pop(randint(0, len(test_entry)-1))\n",
    "    \n",
    "    predictions_cbow = model_cbow.predict_output_word(test_entry, topn=top_values)\n",
    "    predicted_modules_cbow = [x[0] for x in predictions_cbow]\n",
    "    predictions_skipgram = model_skipgram.predict_output_word(test_entry, topn=top_values)\n",
    "    predicted_modules_skipgram = [x[0] for x in predictions_skipgram]\n",
    "    \n",
    "    if missing_dependency in predicted_modules_cbow:\n",
    "        successful_suggestions_cbow += 1\n",
    "    if missing_dependency in predicted_modules_skipgram:\n",
    "        successful_suggestions_skipgram += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: sometimes the word2vec model can output RuntimeWarning, the reasons behind this are unknown for me and need to be further inspected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the statistics for the CBOW variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successful CBOW recommender suggestions: 83\n",
      "number of failed CBOW recommender suggestions: 17\n"
     ]
    }
   ],
   "source": [
    "print('number of successful CBOW recommender suggestions:', successful_suggestions_cbow)\n",
    "print('number of failed CBOW recommender suggestions:', test_iterations - successful_suggestions_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also for the Skip-gram variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successful Skip-gram recommender suggestions: 68\n",
      "number of failed Skip-gram recommender suggestions: 32\n"
     ]
    }
   ],
   "source": [
    "print('number of successful Skip-gram recommender suggestions:', successful_suggestions_skipgram)\n",
    "print('number of failed Skip-gram recommender suggestions:', test_iterations - successful_suggestions_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The limit of 50 suggestions per one recommendation was used\n",
      "The CBOW model was successful in 83.0 % of cases\n",
      "The Skip-gram model was successful in 68.0 % of cases\n"
     ]
    }
   ],
   "source": [
    "print('The limit of', top_values, 'suggestions per one recommendation was used')\n",
    "print('The CBOW model was successful in', (successful_suggestions_cbow / test_iterations)*100, '% of cases')\n",
    "print('The Skip-gram model was successful in', (successful_suggestions_skipgram / test_iterations)*100, '% of cases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
