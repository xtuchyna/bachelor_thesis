{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word2vec model, we will be using the gensim library, which has implementations of both the cbow and skip-gram variant of word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load up our dataset that was preprocessed earlier. We will be using the csv module again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions were devided into individual lines, items in these transactions are separated by ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "with open('extracted_dependencies.csv', 'r') as csv_file:\n",
    "    entries_csv = csv.reader(csv_file, delimiter=',')\n",
    "    entries = list(entries_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the parameters for Word2Vec model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our recommendation system based on word2vec must be specifically tuned to be trained in a correct way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the size - dimensionality of the word vectors. The recommended value is often between 100 - 150, depending on how big the dataset is. For example purposes, we will use the size 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dimension = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another parameter is the window size. This specifies the maximum distance between the current and predicted word within a sentence. In terms of our issue, the items in transaction is like one sentence. In this sentence, we want  \"train\" every word with each other. So, to cover all the cases that can occur, the window size should be the lenght of the longest transaction in entries, so that every word is trained witihin every word present in the same transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "window_size = max([len(transaction) for transaction in entries])\n",
    "print(window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The min_count parameter specifies the minimal count of a word to be recognized. In other words, the model would ignore words that do not satisfy the min_count. For example purposes, we set the min_count to 1, because right now we want to train model with every unique dependency it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter sg is for the training algorithm: 1 for skip-gram; 0 for CBOW. We will train both variants, firstly the CBOW and then skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = 0\n",
    "skip_gram = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of other parameters that you can specify for a better, fine-tuned model. If you are interestered, you can lookup everything in the gensim documentation here:\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.Word2Vec(\n",
    "        entries,\n",
    "        size=vec_dimension,\n",
    "        window=window_size,\n",
    "        min_count=frequency,\n",
    "        sg=cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg = gensim.models.Word2Vec(\n",
    "        entries,\n",
    "        size=vec_dimension,\n",
    "        window=window_size,\n",
    "        min_count=frequency,\n",
    "        sg=skip_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the both variants of model are set up, we can train them. There are also various parameters that can be set for trainig phase, so if you are interested, you can look it up in the documentation mentioned above. The epochs represent number of iterations over the corpus. They are set to be of a one hundred, this is for now just for an example purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14943449, 17526400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.train(entries, total_examples=len(entries), epochs=100)\n",
    "model_sg.train(entries, total_examples=len(entries), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, it can be also saved and loaded for later use. We will save the both variants for later use in the part that is dedicated to results of recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models were successfully saved\n"
     ]
    }
   ],
   "source": [
    "model_cbow.save('dependencies_recommender_w2v_cbow')\n",
    "model_sg.save('dependencies_recommender_w2v_skipgram')\n",
    "print('models were successfully saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
